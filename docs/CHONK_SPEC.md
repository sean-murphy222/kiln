# CHONK - Visual Document Chunking Studio

## Project Overview

CHONK is a local-first, visual document preparation tool for semantic embedding and RAG pipelines. It provides a GUI for refining AI-generated chunk boundaries and testing retrieval before committing to expensive embedding operations.

**Tagline**: "Know your chunks work before you embed them."

**Core Value Proposition**:
- Visual feedback loop BEFORE embedding (no one else does this)
- Test retrieval BEFORE export (the killer feature)
- Local-first (documents never leave your machine)
- Multi-format support (PDF, DOCX, HTML, Markdown, TXT)
- One-time license (no per-page API fees)

**The Core Loop**:
```
DROP FILE â†’ SEE CHUNKS â†’ TEST QUERIES â†’ REFINE â†’ EXPORT JSON
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CHONK                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   LOADERS   â”‚ â†’ â”‚   PARSERS   â”‚ â†’ â”‚    CHUNKERS     â”‚    â”‚
â”‚  â”‚             â”‚   â”‚             â”‚   â”‚                 â”‚    â”‚
â”‚  â”‚ pdf_loader  â”‚   â”‚ layout      â”‚   â”‚ fixed_size      â”‚    â”‚
â”‚  â”‚ docx_loader â”‚   â”‚ semantic    â”‚   â”‚ recursive       â”‚    â”‚
â”‚  â”‚ pptx_loader â”‚   â”‚ table       â”‚   â”‚ semantic        â”‚    â”‚
â”‚  â”‚ html_loader â”‚   â”‚ ocr         â”‚   â”‚ hierarchy       â”‚    â”‚
â”‚  â”‚ md_loader   â”‚   â”‚             â”‚   â”‚ schema_aware    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                â”‚                   â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            UNIFIED DOCUMENT MODEL (UDM)              â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  {                                                   â”‚   â”‚
â”‚  â”‚    "source": "document.pdf",                         â”‚   â”‚
â”‚  â”‚    "blocks": [                                       â”‚   â”‚
â”‚  â”‚      {                                               â”‚   â”‚
â”‚  â”‚        "id": "block_001",                            â”‚   â”‚
â”‚  â”‚        "type": "text|table|image|code|heading",      â”‚   â”‚
â”‚  â”‚        "content": "...",                             â”‚   â”‚
â”‚  â”‚        "bbox": [x1, y1, x2, y2],                     â”‚   â”‚
â”‚  â”‚        "page": 1,                                    â”‚   â”‚
â”‚  â”‚        "parent_id": null,                            â”‚   â”‚
â”‚  â”‚        "metadata": {}                                â”‚   â”‚
â”‚  â”‚      }                                               â”‚   â”‚
â”‚  â”‚    ],                                                â”‚   â”‚
â”‚  â”‚    "chunks": [                                       â”‚   â”‚
â”‚  â”‚      {                                               â”‚   â”‚
â”‚  â”‚        "id": "chunk_001",                            â”‚   â”‚
â”‚  â”‚        "block_ids": ["block_001", "block_002"],      â”‚   â”‚
â”‚  â”‚        "content": "...",                             â”‚   â”‚
â”‚  â”‚        "token_count": 256,                           â”‚   â”‚
â”‚  â”‚        "quality_score": 0.85,                        â”‚   â”‚
â”‚  â”‚        "hierarchy_path": "Section 1 > Subsection A" â”‚   â”‚
â”‚  â”‚      }                                               â”‚   â”‚
â”‚  â”‚    ]                                                 â”‚   â”‚
â”‚  â”‚  }                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 VISUAL EDITOR UI                     â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                    â”‚                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   DOCUMENT VIEW    â”‚    CHUNK PANEL          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                    â”‚                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  [Rendered doc     â”‚  â€¢ Chunk list           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   with overlay     â”‚  â€¢ Token counts         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   showing chunk    â”‚  â€¢ Quality scores       â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   boundaries]      â”‚  â€¢ Hierarchy view       â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                    â”‚  â€¢ Merge/Split buttons  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Click to select   â”‚                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Drag to resize    â”‚  [EXPORT]               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                    â”‚                         â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 RETRIEVAL TESTER                     â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â€¢ Local embedding (all-MiniLM-L6-v2 default)        â”‚   â”‚
â”‚  â”‚  â€¢ Optional: OpenAI text-embedding-3-small           â”‚   â”‚
â”‚  â”‚  â€¢ In-memory vector search (numpy cosine sim)        â”‚   â”‚
â”‚  â”‚  â€¢ Query â†’ top-k chunks with similarity scores       â”‚   â”‚
â”‚  â”‚  â€¢ "Know your chunks work before you embed them"     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    EXPORTERS                         â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â€¢ JSONL (LangChain/LlamaIndex compatible)           â”‚   â”‚
â”‚  â”‚  â€¢ JSON with metadata                                â”‚   â”‚
â”‚  â”‚  â€¢ CSV (simple)                                      â”‚   â”‚
â”‚  â”‚  â€¢ Direct to Chroma/Pinecone (future)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

### Backend (Python)
```
chonk/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ cli.py                 # CLI entry point
â”œâ”€â”€ server.py              # FastAPI server for GUI
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document.py        # Unified Document Model
â”‚   â”œâ”€â”€ loader.py          # Base loader class
â”‚   â”œâ”€â”€ parser.py          # Base parser class
â”‚   â”œâ”€â”€ chunker.py         # Base chunker class
â”‚   â””â”€â”€ exporter.py        # Base exporter class
â”œâ”€â”€ loaders/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf.py             # PyMuPDF + pdfplumber
â”‚   â”œâ”€â”€ docx.py            # python-docx
â”‚   â”œâ”€â”€ pptx.py            # python-pptx
â”‚   â”œâ”€â”€ html.py            # BeautifulSoup
â”‚   â””â”€â”€ markdown.py        # markdown-it
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ layout.py          # Layout detection
â”‚   â”œâ”€â”€ table.py           # Table extraction
â”‚   â”œâ”€â”€ semantic.py        # Sentence/paragraph detection
â”‚   â””â”€â”€ ocr.py             # Tesseract/EasyOCR wrapper
â”œâ”€â”€ chunkers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fixed.py           # Fixed size with overlap
â”‚   â”œâ”€â”€ recursive.py       # Recursive character
â”‚   â”œâ”€â”€ semantic.py        # Embedding-based semantic
â”‚   â””â”€â”€ hierarchy.py       # Heading-aware hierarchical
â”œâ”€â”€ exporters/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ jsonl.py
â”‚   â”œâ”€â”€ json_export.py
â”‚   â””â”€â”€ csv_export.py
â”œâ”€â”€ testing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embedder.py         # Local embedding models
â”‚   â”œâ”€â”€ searcher.py         # In-memory vector search
â”‚   â””â”€â”€ test_suite.py       # Saved test queries (Phase 2)
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ tokens.py          # Token counting (tiktoken)
    â””â”€â”€ quality.py         # Chunk quality scoring
```

### Frontend (Electron + React)
```
chonk-ui/
â”œâ”€â”€ package.json
â”œâ”€â”€ electron/
â”‚   â”œâ”€â”€ main.js            # Electron main process
â”‚   â””â”€â”€ preload.js
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ DocumentViewer.tsx    # PDF.js / doc renderer
â”‚   â”‚   â”œâ”€â”€ ChunkOverlay.tsx      # SVG overlay for boundaries
â”‚   â”‚   â”œâ”€â”€ ChunkPanel.tsx        # Right sidebar
â”‚   â”‚   â”œâ”€â”€ ChunkCard.tsx         # Individual chunk display
â”‚   â”‚   â”œâ”€â”€ QualityBadge.tsx      # Quality score indicator
â”‚   â”‚   â”œâ”€â”€ RetrievalTester.tsx   # Query testing panel
â”‚   â”‚   â”œâ”€â”€ SearchResult.tsx      # Individual search result
â”‚   â”‚   â””â”€â”€ ExportModal.tsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useDocument.ts
â”‚   â”‚   â”œâ”€â”€ useChunks.ts
â”‚   â”‚   â””â”€â”€ useExport.ts
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ chonk.ts              # API calls to Python backend
â””â”€â”€ public/
    â””â”€â”€ index.html
```

---

## Unified Document Model (UDM) Schema

```python
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any
from enum import Enum

class BlockType(Enum):
    TEXT = "text"
    HEADING = "heading"
    TABLE = "table"
    IMAGE = "image"
    CODE = "code"
    LIST = "list"
    FOOTER = "footer"
    HEADER = "header"

@dataclass
class BoundingBox:
    x1: float
    y1: float
    x2: float
    y2: float
    page: int

@dataclass
class Block:
    id: str
    type: BlockType
    content: str
    bbox: Optional[BoundingBox] = None
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 1.0  # Parser confidence score

@dataclass
class Chunk:
    id: str
    block_ids: List[str]
    content: str
    token_count: int
    quality_score: float  # 0-1, computed by quality analyzer
    hierarchy_path: str   # "Section 1 > Subsection A"
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # For visual editor
    is_modified: bool = False
    is_locked: bool = False  # User locked this chunk

@dataclass
class ChonkDocument:
    source: str
    source_type: str  # pdf, docx, pptx, etc.
    blocks: List[Block]
    chunks: List[Chunk]
    page_count: int
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # Processing metadata
    loader_used: str
    parser_used: str
    chunker_used: str
    chunker_config: Dict[str, Any] = field(default_factory=dict)
```

---

## Quality Scoring System

Each chunk gets a quality score (0-1) based on:

```python
def compute_quality_score(chunk: Chunk, document: ChonkDocument) -> float:
    scores = []
    
    # 1. Token count in optimal range (200-500 tokens ideal)
    token_score = 1.0
    if chunk.token_count < 100:
        token_score = chunk.token_count / 100
    elif chunk.token_count > 600:
        token_score = max(0.3, 1 - (chunk.token_count - 600) / 1000)
    scores.append(("token_range", token_score, 0.25))
    
    # 2. Sentence completeness (starts with capital, ends with period)
    content = chunk.content.strip()
    sentence_score = 1.0
    if content and not content[0].isupper():
        sentence_score -= 0.3
    if content and content[-1] not in '.!?:':
        sentence_score -= 0.3
    scores.append(("sentence_complete", max(0, sentence_score), 0.20))
    
    # 3. Hierarchy preservation (heading followed by content)
    hierarchy_score = 1.0
    blocks = [b for b in document.blocks if b.id in chunk.block_ids]
    has_orphan_heading = any(
        b.type == BlockType.HEADING and 
        b.id == chunk.block_ids[-1]  # Heading at end of chunk
        for b in blocks
    )
    if has_orphan_heading:
        hierarchy_score = 0.4
    scores.append(("hierarchy", hierarchy_score, 0.25))
    
    # 4. Table integrity (tables not split)
    table_score = 1.0
    # Check if any table block is partially included
    # (implementation depends on table detection)
    scores.append(("table_integrity", table_score, 0.15))
    
    # 5. Reference completeness (no orphaned references)
    ref_score = 1.0
    # Check for patterns like "see above" or "as shown in" without context
    scores.append(("references", ref_score, 0.15))
    
    # Weighted average
    total = sum(score * weight for _, score, weight in scores)
    return round(total, 3)
```

---

## Retrieval Tester ("Test Before You Embed")

The killer feature that closes the feedback loop. Users can test queries against their chunks BEFORE exporting and embedding elsewhere.

### Why This Matters

| Without Testing | With Testing |
|-----------------|--------------|
| "I think these chunks look right" | "I know these chunks retrieve correctly" |
| Export, embed, build RAG, test, fail, restart | Test before export, fix issues immediately |
| Debugging happens in production | Debugging happens in CHONK |
| Hours wasted on bad chunks | Minutes to validate |

### UI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Document View]              â”‚  [Chunk Panel]              â”‚
â”‚                               â”‚                             â”‚
â”‚   (rendered document)         â”‚   (chunk list)              â”‚
â”‚                               â”‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ” TEST RETRIEVAL                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ "What are the safety requirements for maintenance?"    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  TOP MATCHES:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ðŸŸ¢ 0.89  Chunk 7 (p.3)                               â”‚   â”‚
â”‚  â”‚ "Safety requirements include lockout/tagout..."      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ðŸŸ¡ 0.72  Chunk 12 (p.5)                              â”‚   â”‚
â”‚  â”‚ "Maintenance personnel shall wear protective..."     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ðŸ”´ 0.61  Chunk 3 (p.1)                               â”‚   â”‚
â”‚  â”‚ "This manual covers system maintenance..."           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  ðŸ’¡ Chunk 15 "Safety warnings for hydraulic systems"       â”‚
â”‚     scored 0.58 - consider merging with Chunk 7?           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

```python
from sentence_transformers import SentenceTransformer
from dataclasses import dataclass
from typing import List, Optional
import numpy as np

@dataclass
class SearchResult:
    chunk: Chunk
    score: float
    rank: int

class RetrievalTester:
    """
    Local embedding + search for testing chunk quality.
    Runs entirely on-device, no API keys required.
    """
    
    # Model options (user can choose in settings)
    MODELS = {
        "fast": "all-MiniLM-L6-v2",      # 80MB, fastest
        "balanced": "all-mpnet-base-v2",  # 420MB, better quality
        "accurate": "bge-small-en-v1.5",  # 130MB, modern
    }
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.chunk_embeddings: Optional[np.ndarray] = None
        self.chunks: Optional[List[Chunk]] = None
        self._is_indexed = False
    
    def index_chunks(self, chunks: List[Chunk]) -> None:
        """
        Embed all chunks. Called once after chunking/re-chunking.
        Typically takes 1-5 seconds for 100 chunks.
        """
        self.chunks = chunks
        texts = [c.content for c in chunks]
        self.chunk_embeddings = self.model.encode(
            texts,
            show_progress_bar=False,
            convert_to_numpy=True
        )
        self._is_indexed = True
    
    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """
        Find most similar chunks to query using cosine similarity.
        Returns top_k results sorted by relevance.
        """
        if not self._is_indexed:
            raise ValueError("Must call index_chunks() first")
        
        # Embed the query
        query_embedding = self.model.encode(
            [query],
            convert_to_numpy=True
        )[0]
        
        # Cosine similarity against all chunks
        similarities = np.dot(self.chunk_embeddings, query_embedding) / (
            np.linalg.norm(self.chunk_embeddings, axis=1) * 
            np.linalg.norm(query_embedding)
        )
        
        # Get top k indices
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        return [
            SearchResult(
                chunk=self.chunks[i],
                score=float(similarities[i]),
                rank=rank + 1
            )
            for rank, i in enumerate(top_indices)
        ]
    
    def reindex_if_needed(self, chunks: List[Chunk]) -> None:
        """Re-index only if chunks have changed."""
        if self.chunks is None or len(chunks) != len(self.chunks):
            self.index_chunks(chunks)
            return
        
        # Check if any content changed
        for old, new in zip(self.chunks, chunks):
            if old.content != new.content:
                self.index_chunks(chunks)
                return


# API integration
class ChunkTesterAPI:
    """FastAPI endpoints for retrieval testing."""
    
    def __init__(self):
        self.tester = RetrievalTester()
    
    async def index(self, document_id: str, chunks: List[Chunk]):
        """POST /api/test/index"""
        self.tester.index_chunks(chunks)
        return {"status": "indexed", "chunk_count": len(chunks)}
    
    async def search(self, query: str, top_k: int = 5):
        """POST /api/test/search"""
        results = self.tester.search(query, top_k)
        return {
            "query": query,
            "results": [
                {
                    "chunk_id": r.chunk.id,
                    "score": r.score,
                    "rank": r.rank,
                    "preview": r.chunk.content[:200],
                    "page": r.chunk.metadata.get("page"),
                }
                for r in results
            ]
        }
```

### Model Options

| Model | Size | Speed | Quality | Use Case |
|-------|------|-------|---------|----------|
| `all-MiniLM-L6-v2` | 80MB | ~50ms/query | Good | Default, fast iteration |
| `all-mpnet-base-v2` | 420MB | ~150ms/query | Better | When quality matters |
| `bge-small-en-v1.5` | 130MB | ~80ms/query | Better | Modern alternative |
| OpenAI API | N/A | ~200ms/query | Best | Phase 2, optional |

**Default:** `all-MiniLM-L6-v2` - good enough for testing, fast enough for live preview.

### User Flow

1. User chunks document
2. Chunks are auto-indexed in background (1-5 sec)
3. User types test query in search box
4. Results appear instantly with similarity scores
5. User clicks result â†’ chunk highlights in document view
6. If wrong chunks retrieved â†’ user refines chunking
7. Repeat until satisfied
8. Export with confidence

### Score Interpretation (UI Badges)

| Score | Badge | Meaning |
|-------|-------|---------|
| â‰¥ 0.80 | ðŸŸ¢ | Strong match - this chunk is highly relevant |
| 0.65 - 0.79 | ðŸŸ¡ | Moderate match - probably relevant |
| 0.50 - 0.64 | ðŸŸ  | Weak match - might be relevant |
| < 0.50 | ðŸ”´ | Poor match - likely not relevant |

### Future Enhancements (Phase 2+)

**Test Suites:**
```python
@dataclass
class TestCase:
    query: str
    expected_chunk_ids: List[str]  # Should be in top-k
    excluded_chunk_ids: List[str]  # Should NOT be in top-k

@dataclass  
class TestSuite:
    name: str
    test_cases: List[TestCase]
    
    def run(self, tester: RetrievalTester) -> TestReport:
        """Run all test cases, return pass/fail report."""
        pass
```

**Coverage Analysis:**
```python
def analyze_coverage(chunks: List[Chunk], test_suite: TestSuite) -> CoverageReport:
    """
    Identify chunks that are never retrieved by any test query.
    Helps find dead content or gaps in test coverage.
    """
    pass
```

**Similarity Heatmap:**
```python
def compute_similarity_matrix(chunks: List[Chunk]) -> np.ndarray:
    """
    NxN matrix of chunk-to-chunk similarity.
    Helps identify redundant chunks or merge candidates.
    """
    pass
```

---

## MVP Feature Set

### Phase 1: Core MVP (6-8 weeks solo dev)

**Must Have:**
- [ ] PDF loader (PyMuPDF + pdfplumber hybrid)
- [ ] DOCX loader (python-docx)
- [ ] HTML loader (BeautifulSoup + readability)
- [ ] Markdown loader
- [ ] Plain text loader
- [ ] Basic layout parser (text blocks, headings, tables)
- [ ] Fixed-size chunker with overlap
- [ ] Recursive character chunker
- [ ] Hierarchy-aware chunker (respects headings)
- [ ] Unified Document Model
- [ ] Quality scoring (basic)
- [ ] Electron app shell
- [ ] Document viewer (PDF.js for PDF, HTML render for others)
- [ ] Chunk boundary overlay (colored rectangles)
- [ ] Chunk list panel with token counts
- [ ] Click to select chunk
- [ ] Merge two adjacent chunks (button)
- [ ] Split chunk at cursor position
- [ ] **Retrieval tester (local embedding + search)**
- [ ] **Test query input with live results**
- [ ] **Click search result â†’ highlight chunk in doc**
- [ ] JSONL export
- [ ] JSON export with metadata

**Nice to Have (Phase 1.5):**
- [ ] PPTX loader
- [ ] Semantic chunking (requires embedding model)
- [ ] Drag to resize chunk boundaries
- [ ] Undo/redo
- [ ] Dark mode
- [ ] OpenAI embeddings option for testing

### Phase 2: Differentiation (4-6 weeks)

- [ ] PPTX loader
- [ ] Semantic chunking with embedding preview
- [ ] **Saved test suites (save queries, expected results)**
- [ ] **Coverage analysis (which chunks never retrieved)**
- [ ] **Chunk similarity heatmap**
- [ ] Template system ("remember my settings for this doc type")
- [ ] Batch processing (folder of docs)
- [ ] Chunk comparison view (before/after)
- [ ] Export directly to Chroma/Pinecone
- [ ] Schema-aware chunking (load DTD/XSD)
- [ ] Multi-engine comparison (run pdfplumber AND PyMuPDF, compare)
- [ ] OCR integration for scanned PDFs

### Phase 3: Enterprise (ongoing)

- [ ] Confluence connector
- [ ] SharePoint connector
- [ ] Notion connector
- [ ] S3/GCS batch import
- [ ] Team features (shared templates)
- [ ] API for headless operation
- [ ] Custom chunker plugins

---

## CLI Interface

```bash
# Basic usage
chonk process document.pdf --output chunks.jsonl

# With options
chonk process document.pdf \
  --chunker recursive \
  --chunk-size 400 \
  --overlap 50 \
  --output chunks.jsonl

# Launch GUI
chonk gui

# Launch GUI with file
chonk gui document.pdf

# Batch process
chonk batch ./documents/ --output ./chunks/

# Compare chunking strategies
chonk compare document.pdf --chunkers fixed,recursive,semantic
```

---

## API Endpoints (FastAPI)

```python
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse

app = FastAPI(title="CHONK API")

@app.post("/api/load")
async def load_document(file: UploadFile = File(...)):
    """Load and parse a document, return UDM."""
    pass

@app.post("/api/chunk")
async def chunk_document(document_id: str, config: ChunkConfig):
    """Apply chunking strategy to loaded document."""
    pass

@app.post("/api/chunks/{chunk_id}/split")
async def split_chunk(chunk_id: str, split_position: int):
    """Split a chunk at the given character position."""
    pass

@app.post("/api/chunks/merge")
async def merge_chunks(chunk_ids: List[str]):
    """Merge multiple adjacent chunks."""
    pass

@app.put("/api/chunks/{chunk_id}")
async def update_chunk(chunk_id: str, updates: ChunkUpdate):
    """Update chunk content or metadata."""
    pass

@app.post("/api/export")
async def export_chunks(document_id: str, format: str):
    """Export chunks in specified format."""
    pass

@app.get("/api/quality/{document_id}")
async def get_quality_report(document_id: str):
    """Get quality analysis for all chunks."""
    pass

# Retrieval Testing Endpoints
@app.post("/api/test/index")
async def index_for_testing(document_id: str):
    """Index all chunks for retrieval testing. Called after chunking."""
    pass

@app.post("/api/test/search")
async def test_search(query: str, top_k: int = 5):
    """Search chunks with a test query, return ranked results with scores."""
    pass

@app.get("/api/test/status")
async def get_index_status(document_id: str):
    """Check if chunks are indexed and ready for testing."""
    pass
```

---

## Dependencies

### Python (requirements.txt)
```
# Core
fastapi>=0.100.0
uvicorn>=0.22.0
pydantic>=2.0.0

# Document loading
pymupdf>=1.23.0
pdfplumber>=0.10.0
python-docx>=1.0.0
python-pptx>=0.6.21
beautifulsoup4>=4.12.0
readability-lxml>=0.8.1
markdown-it-py>=3.0.0

# Parsing & NLP
spacy>=3.7.0
tiktoken>=0.5.0

# Retrieval testing (local embeddings)
sentence-transformers>=2.2.0
numpy>=1.24.0

# Optional: OCR
# pytesseract>=0.3.10
# easyocr>=1.7.0

# Optional: OpenAI embeddings for testing
# openai>=1.0.0

# Dev
pytest>=7.4.0
black>=23.0.0
ruff>=0.1.0
```

### Node (package.json)
```json
{
  "name": "chonk-ui",
  "version": "0.1.0",
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "pdfjs-dist": "^3.11.0",
    "@radix-ui/react-*": "latest",
    "tailwindcss": "^3.4.0",
    "zustand": "^4.4.0"
  },
  "devDependencies": {
    "electron": "^28.0.0",
    "electron-builder": "^24.0.0",
    "vite": "^5.0.0",
    "typescript": "^5.3.0"
  }
}
```

---

## File Structure for Claude CLI

When starting development, create this structure:

```
chonk/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CLAUDE.md              # Instructions for Claude CLI
â”œâ”€â”€ src/
â”‚   â””â”€â”€ chonk/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cli.py
â”‚       â”œâ”€â”€ server.py
â”‚       â”œâ”€â”€ core/
â”‚       â”œâ”€â”€ loaders/
â”‚       â”œâ”€â”€ parsers/
â”‚       â”œâ”€â”€ chunkers/
â”‚       â”œâ”€â”€ exporters/
â”‚       â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_loaders.py
â”‚   â”œâ”€â”€ test_chunkers.py
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample.pdf
â”‚       â”œâ”€â”€ sample.docx
â”‚       â””â”€â”€ sample.md
â””â”€â”€ ui/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ electron/
    â””â”€â”€ src/
```

---

## CLAUDE.md (for Claude CLI)

```markdown
# CHONK Development Guide

## Project Overview
CHONK is a visual document chunking tool for RAG pipelines. It loads documents,
parses them into blocks, chunks the blocks, provides a GUI for refinement,
and lets users TEST retrieval before exporting.

**The Core Loop:**
Drop file â†’ Auto-chunk â†’ Live preview â†’ Test queries â†’ Refine â†’ Export

## Key Concepts
- **Block**: A semantic unit from the source document (paragraph, heading, table)
- **Chunk**: A group of blocks that will become one embedding
- **UDM**: Unified Document Model - the internal representation
- **Retrieval Tester**: Local embedding + search to test chunks before export

## Architecture
- Python backend (FastAPI) handles document processing + retrieval testing
- Electron + React frontend provides the visual editor
- sentence-transformers for local embeddings (no API key needed)
- Communication via REST API on localhost

## Development Commands
```bash
# Backend
cd src && uvicorn chonk.server:app --reload

# Frontend
cd ui && npm run dev

# Run Electron
cd ui && npm run electron:dev
```

## Current Focus
MVP Phase 1: 
- PDF/DOCX/HTML/MD/TXT loading
- Fixed + recursive + hierarchy chunking
- Visual editor with merge/split
- Retrieval testing (query â†’ see which chunks match)
- JSONL/JSON export

## Code Style
- Python: Black + Ruff, type hints required
- TypeScript: Strict mode, functional components
- Test all loaders, chunkers, and retrieval tester

## Key Files
- src/chonk/core/document.py - UDM dataclasses
- src/chonk/server.py - API endpoints
- src/chonk/testing/searcher.py - Retrieval tester
- ui/src/components/DocumentViewer.tsx - Main viewer
- ui/src/components/ChunkOverlay.tsx - Visual chunk boundaries
- ui/src/components/RetrievalTester.tsx - Query testing panel
```

---

## Sample Test Fixtures

Include these test documents in tests/fixtures/:

1. **sample.pdf** - 3-page document with:
   - Headings (H1, H2, H3)
   - Body paragraphs
   - One table
   - One image
   - Page numbers/headers

2. **sample.docx** - Similar structure to PDF

3. **sample.md** - Markdown with:
   - Multiple heading levels
   - Code blocks
   - Lists
   - Links

4. **complex.pdf** - Edge cases:
   - Multi-column layout
   - Tables spanning pages
   - Footnotes
   - Scanned page (for OCR testing)

---

## Getting Started Prompt for Claude CLI

When you start working with Claude CLI, use this prompt:

```
I'm building CHONK, a visual document chunking tool for RAG. Read CLAUDE.md for context.

The core value prop: "Drop docs â†’ See chunks â†’ Test queries â†’ Export JSON"

Current task: [describe what you want to build]

Start by:
1. Setting up the Python package structure
2. Implementing the UDM dataclasses in core/document.py
3. Creating the base loader class
4. Implementing the PDF loader
5. Implementing the RetrievalTester with sentence-transformers

Use pytest for testing. Create fixtures as needed.
```
